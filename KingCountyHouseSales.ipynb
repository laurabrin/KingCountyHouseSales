{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Written by: Laura Brin, Sandra Alex & Annabell Rodriguez, On behalf of Norquest College Institute for the CMPT-3510 Machine Learning I Fall course</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using a labeled dataset that contain features representing house characteristics like measurements, number of rooms, location and price. The last one (price) is the class that we are looking to predict based on the rest of the features. The data was collected from King County, USA. This dataset is from Kaggle. More information about the dataset can be found here: https://www.kaggle.com/datasets/harlfoxem/housesalesprediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crucial data processing and analysis libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# loading the house sales csv data\n",
    "df = pd.read_csv(\"kc_house_data.csv\")\n",
    "\n",
    "#Others\n",
    "from IPython.display import Image \n",
    "\n",
    "# This makes it so we are able to see 100 rows when displaying the data\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tendency of the house prices in United States is to grothw. That have been the trend over the last years. In our dataset is difficult to visualize this pattern because it only covers 2 years, from May 2014 to May 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df['month'] = df['date'].to_numpy().astype('datetime64[M]')\n",
    "plt.figure(figsize=(15,6))\n",
    "out_price = df.groupby('month')['price'].median().reset_index(name ='Price')\n",
    "sns.lineplot(x='month',y='Price',data=out_price)\n",
    "plt.title(\"Price vs Date\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, we can see this trend analyzing the data provided by Fred (https://fred.stlouisfed.org/series/MSPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fred = pd.read_csv(\"MSPUS.csv\")\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "sns.lineplot(x='observation_date',y='MSPUS',data=df_fred)\n",
    "plt.title(\"Price vs Date\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "every_nth_xtick = 25\n",
    "plt.xticks(np.arange(0, len(df_fred)+10, every_nth_xtick))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    For people trying to buy or sell a house, this can be problematic. The first ones need to know if the price of the house is fair according to the changes in the market and some other factors that influence its price like physical characteristics (number of rooms, size, location, etc) or the market fluctuation due to inflation, economical crisis, among others. For the second case, when you are trying to sell, you want to get the most from your house, then it is important to take all the factors mentioned before into account. Then having a model that helps people to predict the price of a particular house can be a solution for many. \n",
    "    \n",
    "    This dataset contains 19 features. These are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date - Date of the home sale<br>\n",
    "bedrooms - Number of bedrooms<br>\n",
    "bathrooms - Number of bathrooms, where .5 accounts for a room with a toilet but no shower<br>\n",
    "sqft_living - Square footage of the apartments interior living space<br>\n",
    "sqft_lot - Square footage of the land space<br>\n",
    "floors - Number of floors<br>\n",
    "waterfront - A dummy variable for whether the apartment was overlooking the waterfront or not<br>\n",
    "view - An index from 0 to 4 of how good the view of the property was<br>\n",
    "condition - An index from 1 to 5 on the condition of the apartment<br>\n",
    "grade - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design<br>\n",
    "sqft_above - The square footage of the interior housing space that is above ground level<br>\n",
    "sqft_basement - The square footage of the interior housing space that is below ground level<br>\n",
    "yr_built - The year the house was initially built<br>\n",
    "yr_renovated - The year of the house’s last renovation<br>\n",
    "zipcode - What zipcode area the house is in<br>\n",
    "lat - Lattitude<br>\n",
    "long - Longitude<br>\n",
    "sqft_living15 - The square footage of interior housing living space for the nearest 15 neighbors<br>\n",
    "sqft_lot15 - The square footage of the land lots of the nearest 15 neighbors<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every observation in the dataset represents a house sold in that specific date. The date granularity is daily, it contains the day, month and year in which the house was sold, which means that for a single day we can have multiple records. As we mentioned before, the years represented are 2014 and 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning-Laura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sapce saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning Notes**: <br>\n",
    "need to change date- strip T00 and convert to_datetime <br>\n",
    "yr_renovated change 0 to NaN <br>\n",
    "waterfront to binary <br>\n",
    "grade to categories then encode <br>\n",
    "sqft_living, sqft_lot, sqft_above, sqft_below, sqft_living15, sqft_lot15 could normalize <br>\n",
    "condition and view are both categorical, but as they are currently numerical and ordinal there is no needed cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean=df.copy()\n",
    "df_clean[\"date\"].astype(\"string\").str.rstrip(\"T000000\") \n",
    "df_clean[\"date\"]=df_clean[\"date\"].values.astype(\"datetime64[D]\")\n",
    "df_clean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yr_renovated: NaN for missing years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"yr_renovated\"].replace(0,np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "waterfront:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"waterfront\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"waterfront\"]=df_clean[\"waterfront\"].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grade: categorize and encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"grade\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"grade\"]=pd.cut(df_clean[\"grade\"],bins=[1,4,11,13],labels=[\"low\",\"average\",\"high\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean=pd.get_dummies(df_clean, columns=[\"grade\"],prefix=\"grade\", drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**remove after features described**\n",
    "id - Unique ID for each home sold\n",
    "date - Date of the home sale\n",
    "price - Price of each home sold\n",
    "bedrooms - Number of bedrooms\n",
    "bathrooms - Number of bathrooms, where .5 accounts for a room with a toilet but no shower\n",
    "sqft_living - Square footage of the apartments interior living space\n",
    "sqft_lot - Square footage of the land space\n",
    "floors - Number of floors\n",
    "waterfront - A dummy variable for whether the apartment was overlooking the waterfront or not\n",
    "view - An index from 0 to 4 of how good the view of the property was\n",
    "condition - An index from 1 to 5 on the condition of the apartment,\n",
    "grade - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design.\n",
    "sqft_above - The square footage of the interior housing space that is above ground level\n",
    "sqft_basement - The square footage of the interior housing space that is below ground level\n",
    "yr_built - The year the house was initially built\n",
    "yr_renovated - The year of the house’s last renovation\n",
    "zipcode - What zipcode area the house is in\n",
    "lat - Lattitude\n",
    "long - Longitude\n",
    "sqft_living15 - The square footage of interior housing living space for the nearest 15 neighbors\n",
    "sqft_lot15 - The square footage of the land lots of the nearest 15 neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean.boxplot(column=\"price\")\n",
    "#df_clean.boxplot(column=\"bedrooms\")\n",
    "#df_clean.boxplot(column=\"bathrooms\")\n",
    "#df_clean.boxplot(column=\"sqft_living\")\n",
    "#df_clean.boxplot(column=\"sqft_lot\")\n",
    "#df_clean.boxplot(column=\"floors\")\n",
    "#df_clean.boxplot(column=\"sqft_above\")\n",
    "#df_clean.boxplot(column=\"sqft_basement\")\n",
    "#df_clean.boxplot(column=\"yr_built\")\n",
    "#df_clean.boxplot(column=\"sqft_living15\")\n",
    "#df_clean.boxplot(column=\"sqft_lot15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**insights from boxplots** <br>\n",
    "All features except yr_built and floors showed significant collective outliers. <br> \n",
    "Bedrooms had a single global outlier >30. sqft_living has a potential global outlier at 12000 sqft.  <br>\n",
    "Not checked: lat, long and zipcode as they are geographic location features. <br>\n",
    "Not checked: waterfront as it is binary; condition and grade are catagorical; view is a 1-5 scale; yr_renovated NaN values <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=df_clean.columns\n",
    "features=features.drop([\"id\",\"date\",\"price\",\"grade_average\",\"grade_high\"])\n",
    "graph=1\n",
    "for col in features:\n",
    "    fig=plt.scatter(df_clean[\"price\"],df_clean[col])\n",
    "    plt.xlabel(\"House Price\")\n",
    "    plt.ylabel(f\"{col}\")\n",
    "    plt.title(f\"Figure {graph}:House Price vs {col}\")\n",
    "    plt.show()\n",
    "    graph+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights from scatterplots**: <br>\n",
    "living space square footage appears to have a lower bound where house price will not exceed $200/sqft <br>\n",
    "upper floor sqft has obvious correlation with total living space sqft <br>\n",
    "appears to be a positive correlation with condition of house and price (at least at higher prices) <br>\n",
    "view rating and waterfront did not have obvious strong coorelation with house price. <br>\n",
    "There appears to be a specific lat-long that correlated to the most expensive properties (Bellevue neighbourbhood in Seattle).\n",
    "\n",
    "sqft living and sqft lot each have 1 global outlier to remove. sqft_lot15 has 2 global outliers to remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=df_clean.corr()\n",
    "\n",
    "correlation_heatmap=plt.figure(num=None, figsize=(20,20))\n",
    "correlation_heatmap=sns.heatmap(data=corr,annot=True, fmt='.2f').set(title=\"Figure 18:Heatmap of Correlation for Housing features\")\n",
    "sns.set(font_scale=1.4)\n",
    "\n",
    "correlation_heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights from correlation plot** <br>\n",
    "Price is moderately correlated with sqft_living, sqft_above and sqft_living15. Bedrooms and bathrooms have low correlation with price but moderate correlation with sqft_living. View has a higher correlation than waterfront. While the latitude and longitude had clear patterns in the scatterplots, only the latitue shows a minor correlation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From data visualizations the following cleaning is required: <br>\n",
    "* remove bedroom, sqft_living, sqft_lot, and sqft_lot15 outliers\n",
    "* normalize lat and long values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(df_clean[df_clean[\"bedrooms\"]>30].index, inplace=True)\n",
    "df_clean.drop(df_clean[df_clean[\"sqft_living\"]>13000].index, inplace=True)\n",
    "df_clean.drop(df_clean[df_clean[\"sqft_lot\"]>1500000].index, inplace=True)\n",
    "df_clean.drop(df_clean[df_clean[\"sqft_lot15\"]>800000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "lat_array=df_clean[\"lat\"].values.reshape(-1,1)\n",
    "long_array=df_clean[\"long\"].values.reshape(-1,1)\n",
    "\n",
    "df_clean[\"lat_norm\"]=normalize(lat_array, axis=0)\n",
    "df_clean[\"long_norm\"]=normalize(long_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2=df_clean.corr()\n",
    "\n",
    "correlation_heatmap2=plt.figure(num=None, figsize=(20,20))\n",
    "correlation_heatmap2=sns.heatmap(data=corr2,annot=True, fmt='.2f').set(title=\"Figure 19: Heatmap of Correlation for Housing features\")\n",
    "sns.set(font_scale=1.4)\n",
    "\n",
    "correlation_heatmap2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalizing latitude did not have any markable result, normalizing longitude did have an effect of increasing correlation with price but only to low levels <b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder**\n",
    "column grade needs to be removed from dataset used for regression model \n",
    "\n",
    "could also seperate data into 2 different models- high price and low price, so that the high outliers do not skew the data (<4M, >4M)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Regression: target price will be predicted by using interpolation of the price of the nearest neighbours\n",
    "Decision Tree Regression: target price will be predicted based on a tree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=DecisionTreeRegressor()\n",
    "knn=KNeighborsRegressor()\n",
    "bayes=BayesianRidge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regress=df_clean.copy()\n",
    "df_regress.drop([\"id\",\"lat_norm\",\"long_norm\",\"month\"], inplace=True, axis=1)\n",
    "df_regress[\"yr_renovated\"].replace(np.NaN, pd.NaT, inplace=True)\n",
    "df_regress[\"date\"]=df_regress[\"date\"].map(dt.datetime.toordinal)\n",
    "\n",
    "X_clean = df_regress.loc[:, df_regress.columns != 'price']\n",
    "y_clean = df_regress.loc[:, df_regress.columns == 'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_split, X_valid, y_split, y_valid = train_test_split(X_clean,y_clean, train_size=0.8, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_split, y_split, train_size=0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters to test\n",
    "n_neighbors= [3,5,9,33,66,99]\n",
    "weights=[\"uniform\",\"distance\"]\n",
    "\n",
    "k_random_grid={\"n_neighbors\":n_neighbors, \"weights\":weights}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=RandomizedSearchCV(estimator = knn, param_distributions = k_random_grid, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "min_samples_split = [2, 5, 10]\n",
    "max_features= [\"sqrt\",\"log2\",None]\n",
    "ccp_alpha=[0.01,0.02,0.03]\n",
    "random_grid = {'min_samples_split': min_samples_split,\n",
    "                    \"max_features\": max_features, \"ccp_alpha\":ccp_alpha}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=GridSearchCV(estimator = tree, param_grid = random_grid, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35ed5d7f523cc00db090bb0d1441ff939197785447eebdd396d675dd3643fa93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
